---
title: 'Prepacking: A Simple Method for Fast Prefilling and Increased Throughput in
  Large Language Models'
openreview: LBVD4krAq2
abstract: 'During inference for transformer-based large language models (LLM), prefilling
  is the computation of the key-value (KV) cache for input tokens in the prompt prior
  to autoregressive generation. For longer input prompt lengths, prefilling will incur
  a significant overhead on decoding time. In this work, we highlight the following
  pitfall of prefilling: for batches containing high-varying prompt lengths, significant
  computation is wasted by the standard practice of padding sequences to the maximum
  length. As LLMs increasingly support longer context lengths, potentially up to 10
  million tokens, variations in prompt lengths within a batch become more pronounced.
  To address this, we propose prepacking, a simple yet effective method to optimize
  prefilling computation. To avoid redundant computation on pad tokens, prepacking
  combines prompts of varying lengths into a sequence and packs multiple sequences
  into a compact batch using a bin-packing algorithm. It then modifies the attention
  mask and positional encoding to compute multiple prefilled KV-caches for multiple
  prompts within a single sequence. On standard curated dataset containing prompts
  with varying lengths, we obtain a significant speed and memory efficiency improvements
  as compared to the default padding-based prefilling computation within Huggingface
  across a range of base model configurations and inference serving scenarios.'
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: zhao25e
month: 0
tex_title: 'Prepacking: A Simple Method for Fast Prefilling and Increased Throughput
  in Large Language Models'
firstpage: 4393
lastpage: 4401
page: 4393-4401
order: 4393
cycles: false
bibtex_author: Zhao, Siyan and Israel, Daniel Mingyi and den Broeck, Guy Van and Grover,
  Aditya
author:
- given: Siyan
  family: Zhao
- given: Daniel Mingyi
  family: Israel
- given: Guy Van
  family: Broeck
  prefix: den
- given: Aditya
  family: Grover
date: 2025-04-23
address:
container-title: Proceedings of The 28th International Conference on Artificial Intelligence
  and Statistics
volume: '258'
genre: inproceedings
issued:
  date-parts:
  - 2025
  - 4
  - 23
pdf: https://raw.githubusercontent.com/mlresearch/v258/main/assets/zhao25e/zhao25e.pdf
extras: []
# Format based on Martin Fenner's citeproc: https://blog.front-matter.io/posts/citeproc-yaml-for-bibliographies/
---
