---
title: On the Identifiability of Causal Abstractions
openreview: RKiOGRrABL
abstract: Causal representation learning (CRL) enhances machine learning models’ robustness
  and generalizability by learning structural causal models associated with data-generating
  processes. We focus on a family of CRL methods that uses contrastive data pairs
  in the observable space, generated before and after a random, unknown intervention,
  to identify the latent causal model. (Brehmer et al., 2022) showed that this is
  indeed possible, given that all latent variables can be intervened on individually.
  However, this is a highly restrictive assumption in many systems. In this work,
  we instead assume interventions on arbitrary subsets of latent variables, which
  is more realistic. We introduce a theoretical framework that calculates the degree
  to which we can identify a causal model, given a set of possible interventions,
  up to an abstraction that describes the system at a higher level of granularity.
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: li25g
month: 0
tex_title: On the Identifiability of Causal Abstractions
firstpage: 3241
lastpage: 3249
page: 3241-3249
order: 3241
cycles: false
bibtex_author: Li, Xiusi and Kaba, S{\'e}kou-Oumar and Ravanbakhsh, Siamak
author:
- given: Xiusi
  family: Li
- given: Sékou-Oumar
  family: Kaba
- given: Siamak
  family: Ravanbakhsh
date: 2025-04-23
address:
container-title: Proceedings of The 28th International Conference on Artificial Intelligence
  and Statistics
volume: '258'
genre: inproceedings
issued:
  date-parts:
  - 2025
  - 4
  - 23
pdf: https://raw.githubusercontent.com/mlresearch/v258/main/assets/li25g/li25g.pdf
extras: []
# Format based on Martin Fenner's citeproc: https://blog.front-matter.io/posts/citeproc-yaml-for-bibliographies/
---
