---
title: " Training Neural Samplers with Reverse Diffusive KL Divergence "
software: " https://github.com/jiajunhe98/DiKL "
openreview: " https://openreview.net/forum?id=kREJgA7pV2 "
abstract: " Training generative models to sample from unnormalized density functions
  is an important and challenging task in machine learning.  Traditional training
  methods often rely on the reverse Kullback-Leibler (KL) divergence due to its tractability.
  However, the mode-seeking behavior of reverse KL hinders effective approximation
  of multi-modal target distributions. To address this, we propose to minimize the
  reverse KL along diffusion trajectories of both model and target densities. We refer
  to this objective as the reverse diffusive KL divergence, which allows the model
  to capture multiple modes. Leveraging this objective, we train neural samplers that
  can efficiently generate samples from the target distribution in one step. We demonstrate
  that our method enhances sampling performance across various Boltzmann distributions,
  including both synthetic multi-modal densities and n-body particle systems. "
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: he25a
month: 0
tex_title: " Training Neural Samplers with Reverse Diffusive KL Divergence "
firstpage: 5167
lastpage: 5175
page: 5167-5175
order: 5167
cycles: false
bibtex_author: He, Jiajun and Chen, Wenlin and Zhang, Mingtian and Barber, David and
  Hern{\'a}ndez-Lobato, Jos{\'e} Miguel
author:
- given: Jiajun
  family: He
- given: Wenlin
  family: Chen
- given: Mingtian
  family: Zhang
- given: David
  family: Barber
- given: José Miguel
  family: Hernández-Lobato
date: 2025-04-23
address:
container-title: Proceedings of The 28th International Conference on Artificial Intelligence
  and Statistics
volume: '258'
genre: inproceedings
issued:
  date-parts:
  - 2025
  - 4
  - 23
pdf: https://raw.githubusercontent.com/mlresearch/v258/main/assets/he25a/he25a.pdf
extras: []
# Format based on Martin Fenner's citeproc: https://blog.front-matter.io/posts/citeproc-yaml-for-bibliographies/
---
