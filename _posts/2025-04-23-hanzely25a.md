---
title: 'Sketch-and-Project Meets Newton Method: Global $O(1/k^2)$ Convergence with
  Low-Rank Updates'
openreview: cPbEcEkTYe
abstract: 'In this paper, we propose the first sketch-and-project Newton method with
  the fast $O(1/k^2$) global convergence rate for self-concordant functions. Our method,
  SGN, can be viewed in three ways: i) as a sketch-and-project algorithm projecting
  updates of the Newton method, ii) as a cubically regularized Newton method in the
  sketched subspaces, and iii) as a damped Newton method in the sketched subspaces.
  SGN inherits the best of all three worlds: the cheap iteration costs of the sketch-and-project
  methods, the state-of-the-art $O(1/k^2)$ global convergence rate of the full-rank
  Newton-like methods, and the algorithm simplicity of the damped Newton methods.
  Finally, we demonstrate its comparable empirical performance to the baseline algorithms.'
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: hanzely25a
month: 0
tex_title: 'Sketch-and-Project Meets Newton Method: Global $O(1/k^2)$ Convergence
  with Low-Rank Updates'
firstpage: 3205
lastpage: 3213
page: 3205-3213
order: 3205
cycles: false
bibtex_author: Hanzely, Slavomir
author:
- given: Slavomir
  family: Hanzely
date: 2025-04-23
address:
container-title: Proceedings of The 28th International Conference on Artificial Intelligence
  and Statistics
volume: '258'
genre: inproceedings
issued:
  date-parts:
  - 2025
  - 4
  - 23
pdf: https://raw.githubusercontent.com/mlresearch/v258/main/assets/hanzely25a/hanzely25a.pdf
extras: []
# Format based on Martin Fenner's citeproc: https://blog.front-matter.io/posts/citeproc-yaml-for-bibliographies/
---
