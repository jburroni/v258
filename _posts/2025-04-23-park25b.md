---
title: 'FedBaF: Federated Learning Aggregation Biased by a Foundation Model'
openreview: HEgs74QHRZ
abstract: Foundation models are now a major focus of leading technology organizations
  due to their ability to generalize across diverse tasks. Existing approaches for
  adapting foundation models to new applications often rely on Federated Learning
  (FL) and disclose the foundation model weights to clients when using it to initialize
  the global model. While these methods ensure client data privacy, they compromise
  model and information security. In this paper, we introduce Federated Learning Aggregation
  Biased by a Foundation Model (FedBaF), a novel method for dynamically integrating
  pre-trained foundation model weights during the FL aggregation phase. Unlike conventional
  methods, FedBaF preserves the confidentiality of the foundation model while still
  leveraging its power to train more accurate models, especially in non-IID and adversarial
  scenarios. Our comprehensive experiments use Pre-ResNet and foundation models like
  Vision Transformer to demonstrate that FedBaF not only matches, but often surpasses
  the test accuracy of traditional weight initialization methods by up to 11.4% in
  IID and up to 15.8% in non-IID settings. Additionally, FedBaF applied to a Transformer-based
  language model significantly reduced perplexity by up to 39.2%.
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: park25b
month: 0
tex_title: 'FedBaF: Federated Learning Aggregation Biased by a Foundation Model'
firstpage: 676
lastpage: 684
page: 676-684
order: 676
cycles: false
bibtex_author: Park, Jong-Ik and Pranav, Srinivasa and Moura, Jose M F and Joe-Wong,
  Carlee
author:
- given: Jong-Ik
  family: Park
- given: Srinivasa
  family: Pranav
- given: Jose M F
  family: Moura
- given: Carlee
  family: Joe-Wong
date: 2025-04-23
address:
container-title: Proceedings of The 28th International Conference on Artificial Intelligence
  and Statistics
volume: '258'
genre: inproceedings
issued:
  date-parts:
  - 2025
  - 4
  - 23
pdf: https://raw.githubusercontent.com/mlresearch/v258/main/assets/park25b/park25b.pdf
extras: []
# Format based on Martin Fenner's citeproc: https://blog.front-matter.io/posts/citeproc-yaml-for-bibliographies/
---
