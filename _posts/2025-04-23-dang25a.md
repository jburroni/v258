---
title: Certifiably Quantisation-Robust training and inference of Neural Networks
software: https://github.com/danghue18/Certifiably-Quantisation-Robust-training-and-inference.git
openreview: qtppWP3gXl
abstract: We tackle the problem of computing guarantees for the robustness of neural
  networks against quantisation of their inputs, parameters and activation values.
  In particular, we pose the problem of bounding the worst-case discrepancy between
  the original neural network and all possible quantised ones parametrised by a given
  maximum quantisation diameter $\epsilon > 0$ over a finite dataset. To achieve this,
  we first reformulate the problem  in terms of bilinear optimisation, which can be
  solved for provable bounds on the robustness guarantee. We then show how a quick
  scheme based on interval bound propagation can be developed and implemented during
  training so to allow for the learning of neural networks robust against a continuous
  family of quantisation techniques. We evaluated our methodology on a variety of
  architectures on datasets such as MNIST, F-MNIST and CIFAR10. We demonstrate how
  non-trivial bounds on guaranteed accuracy can be obtained on several architectures
  and how quantisation robustness can be significantly improved through robust training.
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: dang25a
month: 0
tex_title: Certifiably Quantisation-Robust training and inference of Neural Networks
firstpage: 5104
lastpage: 5112
page: 5104-5112
order: 5104
cycles: false
bibtex_author: Dang, Hue and Wicker, Matthew Robert and Botterweck, Goetz and Patane,
  Andrea
author:
- given: Hue
  family: Dang
- given: Matthew Robert
  family: Wicker
- given: Goetz
  family: Botterweck
- given: Andrea
  family: Patane
date: 2025-04-23
address:
container-title: Proceedings of The 28th International Conference on Artificial Intelligence
  and Statistics
volume: '258'
genre: inproceedings
issued:
  date-parts:
  - 2025
  - 4
  - 23
pdf: https://raw.githubusercontent.com/mlresearch/v258/main/assets/dang25a/dang25a.pdf
extras: []
# Format based on Martin Fenner's citeproc: https://blog.front-matter.io/posts/citeproc-yaml-for-bibliographies/
---
