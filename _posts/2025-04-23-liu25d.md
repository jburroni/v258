---
title: " A Shared Low-Rank Adaptation Approach to Personalized RLHF "
software: " https://github.com/DonghaoLee/Shared-LoRA-Reward "
openreview: " https://openreview.net/forum?id=nffyNeZVHS "
abstract: " Reinforcement Learning from Human Feedback (RLHF) has emerged as a pivotal
  technique for aligning artificial intelligence systems with human values, achieving
  remarkable success in fine-tuning large language models. However, existing RLHF
  frameworks often assume that human preferences are relatively homogeneous and can
  be captured by a single, unified reward model. This assumption overlooks the inherent
  diversity and heterogeneity across individuals, limiting the adaptability of RLHF
  to personalized scenarios and risking misalignments that can diminish user satisfaction
  and trust in AI systems. In this paper, we address these challenges by introducing
  Low-Rank Adaptation (LoRA) into the personalized RLHF framework. We apply LoRA in
  the parameter space of the aggregation of all personalized reward functions, thereby
  enabling efficient learning of personalized reward models from potentially limited
  local datasets. Our approach exploits potential shared structures among the local
  ground-truth reward models while allowing for individual adaptation, without relying
  on restrictive assumptions about shared representations as in prior works. We further
  establish sample complexity guarantees for our method. Theoretical analysis demonstrates
  the effectiveness of the proposed approach in capturing both shared and individual-specific
  structures within heterogeneous human preferences, addressing the dual challenge
  of personalization requirements and practical data constraints. Experimental results
  on real-world datasets corroborate the efficiency of our algorithm in the personalized
  RLHF setting. "
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: liu25d
month: 0
tex_title: " A Shared Low-Rank Adaptation Approach to Personalized RLHF "
firstpage: 1405
lastpage: 1413
page: 1405-1413
order: 1405
cycles: false
bibtex_author: Liu, Renpu and Wang, Peng and Li, Donghao and Shen, Cong and Yang,
  Jing
author:
- given: Renpu
  family: Liu
- given: Peng
  family: Wang
- given: Donghao
  family: Li
- given: Cong
  family: Shen
- given: Jing
  family: Yang
date: 2025-04-23
address:
container-title: Proceedings of The 28th International Conference on Artificial Intelligence
  and Statistics
volume: '258'
genre: inproceedings
issued:
  date-parts:
  - 2025
  - 4
  - 23
pdf: https://raw.githubusercontent.com/mlresearch/v258/main/assets/liu25d/liu25d.pdf
extras: []
# Format based on Martin Fenner's citeproc: https://blog.front-matter.io/posts/citeproc-yaml-for-bibliographies/
---
