---
title: Wasserstein Gradient Flow over Variational Parameter Space for Variational
  Inference
openreview: eznvJaqwz2
abstract: Variational Inference (VI) optimizes varia- tional parameters to closely
  align a variational distribution with the true posterior, being ap- proached through
  vanilla gradient descent in black-box VI or natural-gradient descent in natural-gradient
  VI. In this work, we reframe VI as the optimization of an objective that concerns
  probability distributions defined over a variational parameter space. Subsequently,
  we propose Wasserstein gradient descent for solving this optimization, where black-box
  VI and natural-gradient VI can be interpreted as special cases of the proposed Wasserstein
  gradient descent. To enhance the efficiency of optimization, we develop practical
  methods for numerically solving the discrete gradient flows. We validate the effectiveness
  of the pro- posed methods through experiments on syn- thetic and real-world datasets,
  supplemented by theoretical analyses.
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: nguyen25d
month: 0
tex_title: Wasserstein Gradient Flow over Variational Parameter Space for Variational
  Inference
firstpage: 1756
lastpage: 1764
page: 1756-1764
order: 1756
cycles: false
bibtex_author: Nguyen, Dai Hai and Sakurai, Tetsuya and Mamitsuka, Hiroshi
author:
- given: Dai Hai
  family: Nguyen
- given: Tetsuya
  family: Sakurai
- given: Hiroshi
  family: Mamitsuka
date: 2025-04-23
address:
container-title: Proceedings of The 28th International Conference on Artificial Intelligence
  and Statistics
volume: '258'
genre: inproceedings
issued:
  date-parts:
  - 2025
  - 4
  - 23
pdf: https://raw.githubusercontent.com/mlresearch/v258/main/assets/nguyen25d/nguyen25d.pdf
extras: []
# Format based on Martin Fenner's citeproc: https://blog.front-matter.io/posts/citeproc-yaml-for-bibliographies/
---
