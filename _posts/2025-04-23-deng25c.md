---
title: Leveraging Frozen Batch Normalization for Co-Training in Source-Free Domain
  Adaptation
software: https://github.com/SJTU-dxw/BN-SFDA
openreview: NiyGv5qTzI
abstract: Source-free domain adaptation (SFDA) aims to adapt a source model, initially
  trained on a fully-labeled source domain, to an unlabeled target domain. Previous
  works assume that the statistics of Batch Normalization layers in the source model
  capture domain-specific knowledge and directly replace them with target domain-related
  statistics during training. However, our observations indicate that \emph{source-like}
  samples in target data exhibit less deviation in the feature space of the source
  model when preserving the source domain-relevant statistics. In this paper, we propose
  co-training the source model with frozen Batch Normalization layers as part of the
  domain adaptation process. Specifically, we combine the source model and the target
  model to produce more robust pseudo-labels for \emph{global} class clustering and
  to identify more precise neighbor samples for \emph{local} neighbor clustering.
  Extensive experiments validate the effectiveness of our approach, showcasing its
  superiority over current state-of-the-art methods on three standard benchmarks.
  Our codes are available on \url{https://github.com/SJTU-dxw/BN-SFDA.}
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: deng25c
month: 0
tex_title: Leveraging Frozen Batch Normalization for Co-Training in Source-Free Domain
  Adaptation
firstpage: 4825
lastpage: 4833
page: 4825-4833
order: 4825
cycles: false
bibtex_author: Deng, Xianwen and Wang, Yijun and Xue, Zhi
author:
- given: Xianwen
  family: Deng
- given: Yijun
  family: Wang
- given: Zhi
  family: Xue
date: 2025-04-23
address:
container-title: Proceedings of The 28th International Conference on Artificial Intelligence
  and Statistics
volume: '258'
genre: inproceedings
issued:
  date-parts:
  - 2025
  - 4
  - 23
pdf: https://raw.githubusercontent.com/mlresearch/v258/main/assets/deng25c/deng25c.pdf
extras: []
# Format based on Martin Fenner's citeproc: https://blog.front-matter.io/posts/citeproc-yaml-for-bibliographies/
---
