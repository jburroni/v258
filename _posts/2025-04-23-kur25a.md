---
title: " Adaptive Convergence Rates for Log-Concave Maximum Likelihood "
openreview: " https://openreview.net/forum?id=cpGW5oI1vs "
abstract: " We study the task of estimating a log-concave density in $\\mathbb{R}^d$
  using the Maximum Likelihood Estimator, known as the log-concave MLE. We show that
  for every $d \\geq 4$, the log-concave MLE attains an \\emph{adaptive rate} when
  the negative logarithm of the underlying density is the maximum of $k$ affine functions,
  meaning that the estimation error for such a density is significantly lower than
  the minimax rate for the class of log-concave densities. Specifically, we prove
  that for such densities, the risk of the log-concave MLE is of order $c(k) \\cdot
  n^{-\\frac{4}{d}}$ in terms of the Hellinger squared distance. This result complements
  the work of (Kim et al. AoS 2018) and Feng et al. (AoS 2021), who addressed the
  cases $d = 1$ and $d \\in \\{2,3\\}$, respectively. Our proof provides a unified
  and relatively simple approach for all $d \\geq 1$, and is based on techniques from
  stochastic convex geometry and empirical process theory, which may be of independent
  interest. "
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: kur25a
month: 0
tex_title: " Adaptive Convergence Rates for Log-Concave Maximum Likelihood "
firstpage: 1450
lastpage: 1458
page: 1450-1458
order: 1450
cycles: false
bibtex_author: Kur, Gil and Guntuboyina, Aditya
author:
- given: Gil
  family: Kur
- given: Aditya
  family: Guntuboyina
date: 2025-04-23
address:
container-title: Proceedings of The 28th International Conference on Artificial Intelligence
  and Statistics
volume: '258'
genre: inproceedings
issued:
  date-parts:
  - 2025
  - 4
  - 23
pdf: https://raw.githubusercontent.com/mlresearch/v258/main/assets/kur25a/kur25a.pdf
extras: []
# Format based on Martin Fenner's citeproc: https://blog.front-matter.io/posts/citeproc-yaml-for-bibliographies/
---
