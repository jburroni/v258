---
title: " Rate of Model Collapse in Recursive Training "
software: " http://www.github.com/berserank/rate-of-model-collapse/ "
openreview: " https://openreview.net/forum?id=OaXS8nUlfj "
abstract: " Given the ease of creating synthetic data from machine learning models,
  new models can be potentially trained on synthetic data generated by previous models.
  This recursive training process raises concerns about the long-term impact on model
  quality. As models are recursively trained on generated data from previous rounds,
  their ability to capture the nuances of the original human-generated data may degrade.
  This is often referred to as model collapse. In this work, we ask how fast model
  collapse occurs for some well-studied distribution families under maximum likelihood
  (ML or near ML) estimation during recursive training. Surprisingly, even for fundamental
  distributions such as discrete and Gaussian distributions, the exact rate of model
  collapse is unknown. In this work, we theoretically characterize the rate of collapse
  in these fundamental settings and complement it with experimental evaluations. Our
  results show that for discrete distributions, the time to forget a symbol is approximately
  linearly dependent on the number of times it occurred in the original corpus, and
  for Gaussian models, the standard deviation reduces to zero roughly at $n$ iterations,
  where $n$ is the number of samples at each iteration. Both of these findings imply
  that model forgetting, at least in these simple distributions under near ML estimation
  with many samples, takes a long time. "
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: suresh25a
month: 0
tex_title: " Rate of Model Collapse in Recursive Training "
firstpage: 1396
lastpage: 1404
page: 1396-1404
order: 1396
cycles: false
bibtex_author: Suresh, Ananda Theertha and Thangaraj, Andrew and Khandavally, Aditya
  Nanda Kishore
author:
- given: Ananda Theertha
  family: Suresh
- given: Andrew
  family: Thangaraj
- given: Aditya Nanda Kishore
  family: Khandavally
date: 2025-04-23
address:
container-title: Proceedings of The 28th International Conference on Artificial Intelligence
  and Statistics
volume: '258'
genre: inproceedings
issued:
  date-parts:
  - 2025
  - 4
  - 23
pdf: https://raw.githubusercontent.com/mlresearch/v258/main/assets/suresh25a/suresh25a.pdf
extras: []
# Format based on Martin Fenner's citeproc: https://blog.front-matter.io/posts/citeproc-yaml-for-bibliographies/
---
