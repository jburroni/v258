---
title: 'Ordered $\mathcalV$-information Growth: A Fresh Perspective on Shared Information'
software: https://github.com/kentridgeai/OVIG
openreview: wHDQx822qF
abstract: Mutual information (MI) is widely employed as a measure of shared information
  between random variables. However, MI assumes unbounded computational resources—a
  condition rarely met in practice, where predicting a random variable $Y$ from $X$
  must rely on finite resources.  $\mathcal{V}$-information addresses this limitation
  by employing a predictive family $\mathcal{V}$ to emulate computational constraints,
  yielding a directed measure of shared information. Focusing on the mixed setting
  (continuous $X$ and discrete $Y$), here we highlight the upward bias of empirical
  $\mathcal{V}$-information, $\hat I_{\mathcal{V}}(X \rightarrow Y)$, even when $\mathcal{V}$
  is low-complexity (e.g., shallow neural networks). To mitigate this bias, we introduce
  $\mathcal{V}$-Information Growth (VI-Growth), defined as $\\hat I_{\mathcal{V}}(X
  \rightarrow Y) - \hat I_{\mathcal{V}}(X’ \rightarrow Y’)$, where $X’, Y’ \sim P_X
  P_Y$ represent independent variables. While VI-Growth effectively counters over-estimation,
  more complex predictive families may lead to under-estimation. To address this,
  we construct a sequence of predictive families $\mathcal{V}_1, \mathcal{V}_2, \ldots,
  \mathcal{V}$ of increasing complexity and compute the maximum of VI-Growth across
  these families, yielding the ordered VI-Growth (O-VIG). We provide theoretical results
  that justify this approach, showing that O-VIG is a provably tighter lower bound
  for the true $\mathcal{V}$-Information than empirical $\mathcal{V}$-Information
  itself, and exhibits stronger convergence properties than $\mathcal{V}$-Information.
  Empirically, O-VIG alleviates bias and consistently outperforms state-of-the-art
  methods in both MI estimation and dataset complexity estimation, demonstrating its
  practical utility.
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: ghosh25a
month: 0
tex_title: 'Ordered $\mathcal{V}$-information Growth: A Fresh Perspective on Shared
  Information'
firstpage: 793
lastpage: 801
page: 793-801
order: 793
cycles: false
bibtex_author: Ghosh, Rohan and Motani, Mehul
author:
- given: Rohan
  family: Ghosh
- given: Mehul
  family: Motani
date: 2025-04-23
address:
container-title: Proceedings of The 28th International Conference on Artificial Intelligence
  and Statistics
volume: '258'
genre: inproceedings
issued:
  date-parts:
  - 2025
  - 4
  - 23
pdf: https://raw.githubusercontent.com/mlresearch/v258/main/assets/ghosh25a/ghosh25a.pdf
extras: []
# Format based on Martin Fenner's citeproc: https://blog.front-matter.io/posts/citeproc-yaml-for-bibliographies/
---
