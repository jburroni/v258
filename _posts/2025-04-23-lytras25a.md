---
title: " Tamed Langevin sampling under weaker conditions "
openreview: " https://openreview.net/forum?id=7vhymFCZM5 "
abstract: ' Motivated by applications to deep learning which often fail standard Lipschitz
  smoothness requirements, we examine the problem of sampling from distributions that
  are not log-concave and are only weakly dissipative, with log-gradients allowed
  to grow superlinearly at infinity. In terms of structure, we only assume that the
  target distribution satisfies either a Log-Sobolev  or a Poincare inequality and
  a local Lipschitz smoothness assumption with modulus growing possibly polynomially
  at infinity. This set of assumptions greatly exceeds the operational limits of the
  "vanilla" ULA, making sampling from such distributions a highly involved affair.
  To account for this, we introduce a taming scheme which is tailored to the growth
  and decay properties of the target distribution, and we provide explicit non-asymptotic
  guarantees for the proposed sampler in terms of the KL divergence, total variation,
  and Wasserstein distance to the target distribution. '
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: lytras25a
month: 0
tex_title: " Tamed Langevin sampling under weaker conditions "
firstpage: 847
lastpage: 855
page: 847-855
order: 847
cycles: false
bibtex_author: Lytras, Iosif and Mertikopoulos, Panayotis
author:
- given: Iosif
  family: Lytras
- given: Panayotis
  family: Mertikopoulos
date: 2025-04-23
address:
container-title: Proceedings of The 28th International Conference on Artificial Intelligence
  and Statistics
volume: '258'
genre: inproceedings
issued:
  date-parts:
  - 2025
  - 4
  - 23
pdf: https://raw.githubusercontent.com/mlresearch/v258/main/assets/lytras25a/lytras25a.pdf
extras: []
# Format based on Martin Fenner's citeproc: https://blog.front-matter.io/posts/citeproc-yaml-for-bibliographies/
---
