---
title: Analyzing Generative Models by Manifold Entropic Metrics
software: https://github.com/DanielGalperin/ManifoldEntropicMetrics
openreview: WbyCIiFy8k
abstract: Good generative models should not only synthesize high quality data, but
  also utilize interpretable representations that aid human understanding of their
  behavior. However, it is difficult to measure objectively if and to what degree
  desirable properties of disentangled representations have been achieved. Inspired
  by the principle of independent mechanisms, we address this difficulty by introducing
  a novel set of tractable information-theoretic evaluation metrics. We demonstrate
  the usefulness of our metrics on illustrative toy examples and conduct an in-depth
  comparison of various normalizing flow architectures and $\beta$-VAEs on the EMNIST
  dataset. Our method allows to sort latent features by importance and assess the
  amount of residual correlations of the resulting concepts. The most interesting
  finding of our experiments is a ranking of model architectures in terms of their
  inductive bias to converge to aligned and disentangled representations during training.
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: galperin25a
month: 0
tex_title: Analyzing Generative Models by Manifold Entropic Metrics
firstpage: 5077
lastpage: 5085
page: 5077-5085
order: 5077
cycles: false
bibtex_author: Galperin, Daniel and Koethe, Ullrich
author:
- given: Daniel
  family: Galperin
- given: Ullrich
  family: Koethe
date: 2025-04-23
address:
container-title: Proceedings of The 28th International Conference on Artificial Intelligence
  and Statistics
volume: '258'
genre: inproceedings
issued:
  date-parts:
  - 2025
  - 4
  - 23
pdf: https://raw.githubusercontent.com/mlresearch/v258/main/assets/galperin25a/galperin25a.pdf
extras: []
# Format based on Martin Fenner's citeproc: https://blog.front-matter.io/posts/citeproc-yaml-for-bibliographies/
---
