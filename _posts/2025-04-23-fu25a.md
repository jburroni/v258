---
title: " Choice is what matters after Attention "
openreview: " https://openreview.net/forum?id=Lz1IkjFrYe "
abstract: ' The decoding strategies widely used in large language models (LLMs) today
  are Top-$p$ Sampling and Top-$k$ Sampling, both of which are methods situated between
  greedy decoding and random sampling. Inspired by the concept of loss aversion from
  prospect theory in behavioral economics, and the endowment effect as highlighted
  by Richard H. Thaler, the 2017 Nobel Memorial Prize in Economic Sciences — particularly
  the principle that "the negative utility of an equivalent loss is approximately
  twice the positive utility of a comparable gain" — we have developed a new decoding
  strategy called Loss Sampling. We have demonstrated the effectiveness and validity
  of our method on several LLMs, including Llama-2, Llama-3 and Mistral. Our approach
  improves text quality by 4-30% across four pure text tasks while maintaining diversity
  in text generation. Furthermore, we also extend our method to multimodal large models
  (LMs) and Beam Search, demonstrating the effectiveness and versatility of Loss Sampling
  with improvements ranging from 1-10%. '
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: fu25a
month: 0
tex_title: " Choice is what matters after Attention "
firstpage: 262
lastpage: 270
page: 262-270
order: 262
cycles: false
bibtex_author: Fu, Chenhan and Wang, Guoming and Li, Juncheng and Lu, Rongxing and
  Tang, Siliang
author:
- given: Chenhan
  family: Fu
- given: Guoming
  family: Wang
- given: Juncheng
  family: Li
- given: Rongxing
  family: Lu
- given: Siliang
  family: Tang
date: 2025-04-23
address:
container-title: Proceedings of The 28th International Conference on Artificial Intelligence
  and Statistics
volume: '258'
genre: inproceedings
issued:
  date-parts:
  - 2025
  - 4
  - 23
pdf: https://raw.githubusercontent.com/mlresearch/v258/main/assets/fu25a/fu25a.pdf
extras: []
# Format based on Martin Fenner's citeproc: https://blog.front-matter.io/posts/citeproc-yaml-for-bibliographies/
---
