---
title: Learning Laplacian Positional Encodings for Heterophilous Graphs
software: https://github.com/MLD3/LearningLaplacianPEs
openreview: s6ljg6uX9C
abstract: In this work, we theoretically demonstrate that current graph positional
  encodings (PEs) are not beneficial and could potentially hurt performance in tasks
  involving heterophilous graphs, where nodes that are close tend to have different
  labels. This limitation is critical as many real-world networks exhibit heterophily,
  and even highly homophilous graphs can contain local regions of strong heterophily.
  To address this limitation, we propose Learnable Laplacian Positional Encodings
  (LLPE), a new PE that leverages the full spectrum of the graph Laplacian, enabling
  them to capture graph structure on both homophilous and heterophilous graphs. Theoretically,
  we prove LLPEâ€™s ability to approximate a general class of graph distances and demonstrate
  its generalization properties. Empirically, our evaluation on 12 benchmarks demonstrates
  that LLPE improves accuracy across a variety of GNNs, including graph transformers,
  by up to 35% and 14% on synthetic and real-world graphs, respectively. Going forward,
  our work represents a significant step towards developing PEs that effectively capture
  complex structures in heterophilous graphs.
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: ito25a
month: 0
tex_title: Learning Laplacian Positional Encodings for Heterophilous Graphs
firstpage: 2755
lastpage: 2763
page: 2755-2763
order: 2755
cycles: false
bibtex_author: Ito, Michael and Zhu, Jiong and Chen, Dexiong and Koutra, Danai and
  Wiens, Jenna
author:
- given: Michael
  family: Ito
- given: Jiong
  family: Zhu
- given: Dexiong
  family: Chen
- given: Danai
  family: Koutra
- given: Jenna
  family: Wiens
date: 2025-04-23
address:
container-title: Proceedings of The 28th International Conference on Artificial Intelligence
  and Statistics
volume: '258'
genre: inproceedings
issued:
  date-parts:
  - 2025
  - 4
  - 23
pdf: https://raw.githubusercontent.com/mlresearch/v258/main/assets/ito25a/ito25a.pdf
extras: []
# Format based on Martin Fenner's citeproc: https://blog.front-matter.io/posts/citeproc-yaml-for-bibliographies/
---
