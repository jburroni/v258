---
title: 'Calm Composite Losses: Being Improper Yet Proper Composite'
openreview: xmZaLoKHdQ
abstract: Strict proper losses are fundamental loss functions inducing classifiers
  capable of estimating class probabilities. While practitioners have devised many
  loss functions, their properness is often unverified. In this paper, we identify
  several losses as improper, calling into question the validity of class probability
  estimates derived from their simplex-projected outputs. Nevertheless, we show that
  these losses are strictly proper composite with appropriate link functions, allowing
  predictions to be mapped into true class probabilities. We invent the calmness condition,
  which we prove suffices to identify that a loss has a strictly proper composite
  representation, and provide the general form of the inverse link. To further understand
  proper composite losses, we explore proper composite losses through the framework
  of property elicitation, revealing a connection between inverse link functions and
  Bregman projections. Numerical simulations are provided to demonstrate the behavior
  of proper composite losses and the effectiveness of the inverse link function.
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: bao25b
month: 0
tex_title: 'Calm Composite Losses: Being Improper Yet Proper Composite'
firstpage: 2800
lastpage: 2808
page: 2800-2808
order: 2800
cycles: false
bibtex_author: Bao, Han and Charoenphakdee, Nontawat
author:
- given: Han
  family: Bao
- given: Nontawat
  family: Charoenphakdee
date: 2025-04-23
address:
container-title: Proceedings of The 28th International Conference on Artificial Intelligence
  and Statistics
volume: '258'
genre: inproceedings
issued:
  date-parts:
  - 2025
  - 4
  - 23
pdf: https://raw.githubusercontent.com/mlresearch/v258/main/assets/bao25b/bao25b.pdf
extras: []
# Format based on Martin Fenner's citeproc: https://blog.front-matter.io/posts/citeproc-yaml-for-bibliographies/
---
