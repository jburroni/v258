---
title: Fairness Risks for Group-Conditionally Missing Demographics
software: https://tinyurl.com/4wndtfbb
openreview: AcX96FA6Ck
abstract: Fairness-aware classification models have gained increasing attention in
  recent years as concerns grow on discrimination against some demographic groups.
  Most existing models require full knowledge of the sensitive features, which can
  be impractical due to privacy, legal issues, and an individualâ€™s fear of discrimination.
  The key challenge we will address is the group dependency of the unavailability,
  e.g., people of some age range may be more reluctant to reveal their age. Our solution
  augments general fairness risks with probabilistic imputations of the sensitive
  features, while jointly learning the group-conditionally missing probabilities in
  a variational auto-encoder. Our model is demonstrated effective on both image and
  tabular datasets, achieving an improved balance between accuracy and fairness.
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: jiang25b
month: 0
tex_title: Fairness Risks for Group-Conditionally Missing Demographics
firstpage: 3520
lastpage: 3528
page: 3520-3528
order: 3520
cycles: false
bibtex_author: Jiang, Kaiqi and Fan, Wenzhe and Li, Mao and Zhang, Xinhua
author:
- given: Kaiqi
  family: Jiang
- given: Wenzhe
  family: Fan
- given: Mao
  family: Li
- given: Xinhua
  family: Zhang
date: 2025-04-23
address:
container-title: Proceedings of The 28th International Conference on Artificial Intelligence
  and Statistics
volume: '258'
genre: inproceedings
issued:
  date-parts:
  - 2025
  - 4
  - 23
pdf: https://raw.githubusercontent.com/mlresearch/v258/main/assets/jiang25b/jiang25b.pdf
extras: []
# Format based on Martin Fenner's citeproc: https://blog.front-matter.io/posts/citeproc-yaml-for-bibliographies/
---
