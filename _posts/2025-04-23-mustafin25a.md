---
title: " MDP Geometry, Normalization and Reward Balancing Solvers "
software: " https://github.com/gaarsmu/MDP-Geometry-Normalization-and-Reward-Balancing-Solvers "
openreview: " https://openreview.net/forum?id=y7wGcBog9X "
abstract: " We present a new geometric interpretation of Markov Decision Processes
  (MDPs) with a natural normalization procedure that allows us to adjust the value
  function at each state without altering the advantage of any action with respect
  to any policy. This advantage-preserving transformation of the MDP motivates a class
  of algorithms which we call \\emph{Reward Balancing}, which solve MDPs by iterating
  through these transformations, until an approximately optimal policy can be trivially
  found.  We provide a convergence analysis of several algorithms in this class, in
  particular showing that for MDPs for unknown transition probabilities we can improve
  upon state-of-the-art sample complexity results. "
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: mustafin25a
month: 0
tex_title: " MDP Geometry, Normalization and Reward Balancing Solvers "
firstpage: 2476
lastpage: 2484
page: 2476-2484
order: 2476
cycles: false
bibtex_author: Mustafin, Arsenii and Pakharev, Aleksei and Olshevsky, Alex and Paschalidis,
  Ioannis
author:
- given: Arsenii
  family: Mustafin
- given: Aleksei
  family: Pakharev
- given: Alex
  family: Olshevsky
- given: Ioannis
  family: Paschalidis
date: 2025-04-23
address:
container-title: Proceedings of The 28th International Conference on Artificial Intelligence
  and Statistics
volume: '258'
genre: inproceedings
issued:
  date-parts:
  - 2025
  - 4
  - 23
pdf: https://raw.githubusercontent.com/mlresearch/v258/main/assets/mustafin25a/mustafin25a.pdf
extras: []
# Format based on Martin Fenner's citeproc: https://blog.front-matter.io/posts/citeproc-yaml-for-bibliographies/
---
