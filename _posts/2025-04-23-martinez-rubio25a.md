---
title: Accelerated Methods for Riemannian Min-Max Optimization Ensuring Bounded Geometric
  Penalties
openreview: KskYMxXVKX
abstract: 'In this work, we study optimization problems of the form $\min_x \max_y
  f(x, y)$, where $f(x, y)$ is defined on a product Riemannian manifold $\mathcal{M}
  \times \mathcal{N}$ and is $\mu_x$-strongly geodesically convex (g-convex) in $x$
  and $\mu_y$-strongly g-concave in $y$, for $\mu_x, \mu_y \geq 0$. We design accelerated
  methods when $f$ is $(L_x, L_y, L_{xy})$-smooth and $\mathcal{M}$, $\mathcal{N}$
  are Hadamard. To that aim we introduce new g-convex optimization results, of independent
  interest: we show global linear convergence for metric-projected Riemannian gradient
  descent and improve existing accelerated methods by reducing geometric constants.
  Additionally, we complete the analysis of two previous works applying to the Riemannian
  min-max case by removing an assumption about iterates staying in a pre-specified
  compact set.'
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: martinez-rubio25a
month: 0
tex_title: Accelerated Methods for Riemannian Min-Max Optimization Ensuring Bounded
  Geometric Penalties
firstpage: 280
lastpage: 288
page: 280-288
order: 280
cycles: false
bibtex_author: Mart{\'i}nez-Rubio, David and Roux, Christophe and Criscitiello, Christopher
  and Pokutta, Sebastian
author:
- given: David
  family: Mart√≠nez-Rubio
- given: Christophe
  family: Roux
- given: Christopher
  family: Criscitiello
- given: Sebastian
  family: Pokutta
date: 2025-04-23
address:
container-title: Proceedings of The 28th International Conference on Artificial Intelligence
  and Statistics
volume: '258'
genre: inproceedings
issued:
  date-parts:
  - 2025
  - 4
  - 23
pdf: https://raw.githubusercontent.com/mlresearch/v258/main/assets/martinez-rubio25a/martinez-rubio25a.pdf
extras: []
# Format based on Martin Fenner's citeproc: https://blog.front-matter.io/posts/citeproc-yaml-for-bibliographies/
---
