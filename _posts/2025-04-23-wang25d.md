---
title: Prior-Fitted Networks Scale to Larger Datasets When Treated as Weak Learners
software: https://github.com/yxzwang/BoostPFN
openreview: yGL5KBqnl4
abstract: Prior-Fitted Networks (PFNs) have recently been proposed to efficiently
  perform tabular classification tasks. Although they achieve good performance on
  small datasets, they encounter limitations with larger datasets. These limitations
  include significant memory consumption and increased computational complexity, primarily
  due to the impracticality of incorporating all training samples as inputs within
  these networks. To address these challenges, we investigate the fitting assumption
  for PFNs and input samples. Building on this understanding, we propose \emph{BoostPFN}
  designed to enhance the performance of these networks, especially for large-scale
  datasets. We also theoretically validate the convergence of BoostPFN and our empirical
  results demonstrate that the BoostPFN method can outperform standard PFNs with the
  same size of training samples in large datasets and achieve a significant acceleration
  in training times compared to other established baselines in the field, including
  widely-used Gradient Boosting Decision Trees (GBDTs), deep learning methods and
  AutoML systems. High performance is maintained for up to 50x of the pre-training
  size of PFNs, substantially extending the limit of training samples. Through this
  work, we address the challenges of efficiently handling large datasets via PFN-based
  models, paving the way for faster and more effective tabular data classification
  training and prediction process.
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: wang25d
month: 0
tex_title: Prior-Fitted Networks Scale to Larger Datasets When Treated as Weak Learners
firstpage: 1090
lastpage: 1098
page: 1090-1098
order: 1090
cycles: false
bibtex_author: Wang, Yuxin and Jiang, Botian and Guo, Yiran and Gan, Quan and Wipf,
  David and Huang, Xuanjing and Qiu, Xipeng
author:
- given: Yuxin
  family: Wang
- given: Botian
  family: Jiang
- given: Yiran
  family: Guo
- given: Quan
  family: Gan
- given: David
  family: Wipf
- given: Xuanjing
  family: Huang
- given: Xipeng
  family: Qiu
date: 2025-04-23
address:
container-title: Proceedings of The 28th International Conference on Artificial Intelligence
  and Statistics
volume: '258'
genre: inproceedings
issued:
  date-parts:
  - 2025
  - 4
  - 23
pdf: https://raw.githubusercontent.com/mlresearch/v258/main/assets/wang25d/wang25d.pdf
extras: []
# Format based on Martin Fenner's citeproc: https://blog.front-matter.io/posts/citeproc-yaml-for-bibliographies/
---
