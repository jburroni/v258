---
title: Visualizing token importance for black-box language models
software: https://github.com/vanderschaarlab/visualizing-token-importance
openreview: ilNQ2m4GTy
abstract: We consider the problem of auditing \emph{black-box} large language models
  (LLMs) to ensure they behave reliably when deployed in production settings, particularly
  in high-stakes domains such as legal, medical, and regulatory compliance. Existing
  approaches for LLM auditing often focus on isolated aspects of model behavior, such
  as detecting specific biases or evaluating fairness. We are interested in a more
  general questionâ€”can we understand how the outputs of black-box LLMs depend on \emph{each
  input token}? There is a critical need to have such tools in real-world applications
  that rely on inaccessible API endpoints to language models. However, this is a highly
  non-trivial problem, as LLMs are stochastic functions (i.e. two outputs will be
  different by chance), while computing prompt-level gradients to approximate input
  sensitivity is infeasible. To address this, we propose Distribution-Based Sensitivity
  Analysis (DBSA), a lightweight model-agnostic procedure to evaluate the sensitivity
  of the output of a language model for each input token, without making any distributional
  assumptions about the LLM. DBSA is developed as a \emph{practical tool} for practitioners,
  enabling quick, plug-and-play visual exploration of LLMs reliance on specific input
  tokens. Through illustrative examples, we demonstrate how DBSA can enable users
  to inspect LLM inputs and find sensitivities that may be overlooked by existing
  LLM interpretability methods.
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: rauba25a
month: 0
tex_title: Visualizing token importance for black-box language models
firstpage: 4105
lastpage: 4113
page: 4105-4113
order: 4105
cycles: false
bibtex_author: Rauba, Paulius and Wei, Qiyao and van der Schaar, Mihaela
author:
- given: Paulius
  family: Rauba
- given: Qiyao
  family: Wei
- given: Mihaela
  family: Schaar
  prefix: van der
date: 2025-04-23
address:
container-title: Proceedings of The 28th International Conference on Artificial Intelligence
  and Statistics
volume: '258'
genre: inproceedings
issued:
  date-parts:
  - 2025
  - 4
  - 23
pdf: https://raw.githubusercontent.com/mlresearch/v258/main/assets/rauba25a/rauba25a.pdf
extras: []
# Format based on Martin Fenner's citeproc: https://blog.front-matter.io/posts/citeproc-yaml-for-bibliographies/
---
