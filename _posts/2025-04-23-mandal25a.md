---
title: Performative Reinforcement Learning with Linear Markov Decision Process
openreview: ADsGXBwpck
abstract: We study the setting of \emph{performative reinforcement learning} where
  the deployed policy affects both the reward, and the transition of the underlying
  Markov decision process. Prior work (Mandal et al., 2023)  has addressed this problem
  under the tabular setting and established last-iterate convergence of repeated retraining
  with iteration complexity explicitly depending on the number of states. In this
  work, we generalize the results to \emph{linear Markov decision processes} which
  is the primary theoretical model of large-scale MDPs. The main challenge with linear
  MDP is that the regularized objective is no longer strongly convex and we want a
  bound that scales with the dimension of the features, rather than states which can
  be infinite. Our first result shows that repeatedly optimizing a regularized objective
  converges to a \emph{performatively stable policy}. In the absence of strong convexity,
  our analysis leverages a new recurrence relation that uses a specific linear combination
  of optimal dual solutions for proving convergence. We then tackle the finite sample
  setting where the learner has access to a set of trajectories drawn from the current
  policy. We consider a reparametrized version of the primal problem, and construct
  an empirical Lagrangian which is to be optimized from the samples. We show that,
  under a \emph{bounded coverage} condition, repeatedly solving a saddle point of
  this empirical Lagrangian converges to a performatively stable solution, and also
  construct a primal-dual algorithm that solves the empirical Lagrangian efficiently.
  Finally, we show several applications of the general framework of performative RL
  including multi-agent systems.
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: mandal25a
month: 0
tex_title: Performative Reinforcement Learning with Linear Markov Decision Process
firstpage: 3232
lastpage: 3240
page: 3232-3240
order: 3232
cycles: false
bibtex_author: Mandal, Debmalya and Radanovic, Goran
author:
- given: Debmalya
  family: Mandal
- given: Goran
  family: Radanovic
date: 2025-04-23
address:
container-title: Proceedings of The 28th International Conference on Artificial Intelligence
  and Statistics
volume: '258'
genre: inproceedings
issued:
  date-parts:
  - 2025
  - 4
  - 23
pdf: https://raw.githubusercontent.com/mlresearch/v258/main/assets/mandal25a/mandal25a.pdf
extras: []
# Format based on Martin Fenner's citeproc: https://blog.front-matter.io/posts/citeproc-yaml-for-bibliographies/
---
