---
title: Generalization Lower Bounds for GD and SGD in Smooth Stochastic Convex Optimization
openreview: GFl42W9tYC
abstract: This work studies the generalization error of gradient methods. More specifically,
  we focus on how training steps $T$ and step-size $\eta$ might affect generalization
  in smooth stochastic convex optimization (SCO) problems. Recent works show that
  in some cases longer training can hurt generalization. Our work reexamines this
  for smooth SCO and find that the conclusion can be case-dependent. In particular,
  we first study SCO problems when the loss is \emph{realizable}, i.e. an optimal
  solution minimizes all the data points.  Our work provides excess risk lower bounds
  for Gradient Descent (GD) and Stochastic Gradient Descent (SGD) and finds that longer
  training may not hurt generalization. In the short training scenario $\eta T = O(n)$
  ($n$ is sample size), our lower bounds tightly match and certify the respective
  upper bounds. However, for the long training scenario where $\eta T =O(n)$, our
  analysis reveals a gap between the lower and upper bounds, indicating that longer
  training does hurt generalization for realizable objectives.  A conjecture is proposed
  that the gap can be closed by improving upper bounds, supported by analyses in two
  special instances. Moreover, besides the realizable setup, we also provide first
  tight excess risk lower bounds for GD and SGD under the general non-realizable smooth
  SCO setting, suggesting that existing stability analyses are tight in step-size
  and iteration dependence, and that overfitting provably happens when there is no
  interpolating minimum.
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: zhang25a
month: 0
tex_title: Generalization Lower Bounds for GD and SGD in Smooth Stochastic Convex
  Optimization
firstpage: 334
lastpage: 342
page: 334-342
order: 334
cycles: false
bibtex_author: Zhang, Peiyuan and Teng, Jiaye and Zhang, Jingzhao
author:
- given: Peiyuan
  family: Zhang
- given: Jiaye
  family: Teng
- given: Jingzhao
  family: Zhang
date: 2025-04-23
address:
container-title: Proceedings of The 28th International Conference on Artificial Intelligence
  and Statistics
volume: '258'
genre: inproceedings
issued:
  date-parts:
  - 2025
  - 4
  - 23
pdf: https://raw.githubusercontent.com/mlresearch/v258/main/assets/zhang25a/zhang25a.pdf
extras: []
# Format based on Martin Fenner's citeproc: https://blog.front-matter.io/posts/citeproc-yaml-for-bibliographies/
---
