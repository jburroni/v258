---
title: " Parabolic Continual Learning "
openreview: " https://openreview.net/forum?id=7gausJk3jB "
abstract: " Regularizing continual learning techniques is important for anticipating
  algorithmic behavior under new realizations of data.  We introduce a new approach
  to continual learning by imposing the properties of a parabolic partial differential
  equation (PDE) to regularize the expected behavior of the loss over time. This class
  of parabolic PDEs has a number of favorable properties that allow us to analyze
  the error incurred through forgetting and the error induced through generalization.
  Specifically, we do this through imposing boundary conditions where the boundary
  is given by a memory buffer. By using the memory buffer as a boundary, we can enforce
  long term dependencies by bounding the expected error by the boundary loss. Finally,
  we illustrate the empirical performance of the method on a series of continual learning
  tasks. "
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: yang25b
month: 0
tex_title: " Parabolic Continual Learning "
firstpage: 2620
lastpage: 2628
page: 2620-2628
order: 2620
cycles: false
bibtex_author: Yang, Haoming and Hasan, Ali and Tarokh, Vahid
author:
- given: Haoming
  family: Yang
- given: Ali
  family: Hasan
- given: Vahid
  family: Tarokh
date: 2025-04-23
address:
container-title: Proceedings of The 28th International Conference on Artificial Intelligence
  and Statistics
volume: '258'
genre: inproceedings
issued:
  date-parts:
  - 2025
  - 4
  - 23
pdf: https://raw.githubusercontent.com/mlresearch/v258/main/assets/yang25b/yang25b.pdf
extras: []
# Format based on Martin Fenner's citeproc: https://blog.front-matter.io/posts/citeproc-yaml-for-bibliographies/
---
