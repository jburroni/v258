---
title: Mean-Field Microcanonical Gradient Descent
software: https://github.com/MarcusHaggbom/mf-mgdm
openreview: Epaf0FSr9F
abstract: Microcanonical gradient descent is a sampling procedure for energy-based
  models allowing for efficient sampling of distributions in high dimension. It works
  by transporting samples from a high-entropy distribution, such as Gaussian white
  noise, to a low-energy region using gradient descent. We put this model in the framework
  of normalizing flows, showing how it can often overfit by losing an unnecessary
  amount of entropy in the descent. As a remedy, we propose a mean-field microcanonical
  gradient descent that samples several weakly coupled data points simultaneously,
  allowing for better control of the entropy loss while paying little in terms of
  likelihood fit. We study these models in the context of stationary time series and
  2D textures.
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: haggbom25a
month: 0
tex_title: Mean-Field Microcanonical Gradient Descent
firstpage: 5185
lastpage: 5193
page: 5185-5193
order: 5185
cycles: false
bibtex_author: H{\"a}ggbom, Marcus and Karlsmark, Morten and And{\'e}n, Joakim
author:
- given: Marcus
  family: Häggbom
- given: Morten
  family: Karlsmark
- given: Joakim
  family: Andén
date: 2025-04-23
address:
container-title: Proceedings of The 28th International Conference on Artificial Intelligence
  and Statistics
volume: '258'
genre: inproceedings
issued:
  date-parts:
  - 2025
  - 4
  - 23
pdf: https://raw.githubusercontent.com/mlresearch/v258/main/assets/haggbom25a/haggbom25a.pdf
extras: []
# Format based on Martin Fenner's citeproc: https://blog.front-matter.io/posts/citeproc-yaml-for-bibliographies/
---
