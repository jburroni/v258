---
title: " LMEraser: Large Model Unlearning via Adaptive Prompt Tuning "
software: " https://github.com/lmeraser/lmeraser "
openreview: " https://openreview.net/forum?id=gJkLbMH9zR "
abstract: " To address the growing demand for privacy protection in machine learning,
  we propose an efficient and exact machine unlearning method for Large Models, called
  LMEraser. LMEraser takes a divide-and-conquer strategy with an adaptive prompt tuning
  mechanism to isolate data influence effectively. The training dataset is partitioned
  into public and private datasets. Public data are used to train the backbone of
  the model. Private data are clustered based on their diversity, and each cluster
  tunes a tailored prompt independently. This approach enables targeted unlearning
  by updating affected prompts, significantly reduces unlearning costs and maintains
  high model performance. Evaluations show that LMEraser reduces unlearning costs
  by 100 times compared to prior work without compromising model utility. "
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: xu25e
month: 0
tex_title: " LMEraser: Large Model Unlearning via Adaptive Prompt Tuning "
firstpage: 2026
lastpage: 2034
page: 2026-2034
order: 2026
cycles: false
bibtex_author: Xu, Jie and Wu, Zihan and Wang, Cong and Jia, Xiaohua
author:
- given: Jie
  family: Xu
- given: Zihan
  family: Wu
- given: Cong
  family: Wang
- given: Xiaohua
  family: Jia
date: 2025-04-23
address:
container-title: Proceedings of The 28th International Conference on Artificial Intelligence
  and Statistics
volume: '258'
genre: inproceedings
issued:
  date-parts:
  - 2025
  - 4
  - 23
pdf: https://raw.githubusercontent.com/mlresearch/v258/main/assets/xu25e/xu25e.pdf
extras: []
# Format based on Martin Fenner's citeproc: https://blog.front-matter.io/posts/citeproc-yaml-for-bibliographies/
---
